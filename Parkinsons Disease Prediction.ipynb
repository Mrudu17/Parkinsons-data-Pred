{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38c8019e-4463-4e74-aece-5a9521a6f73a",
   "metadata": {},
   "source": [
    "PARKINSONS DISEASE PREDICTION----PROJECT 2----S.K.MruduvaniDataset -\n",
    "parkinsons.data Dependent Variable - Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "152999e8-64a3-41e3-b210-7b4c9477e971",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid non-printable character U+00A0 (3835131215.py, line 58)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 58\u001b[1;36m\u001b[0m\n\u001b[1;33m    In \\[13\\]:\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid non-printable character U+00A0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    #Importing the liabraries\n",
    "    import warnings\n",
    "    import ydata_profiling as pf\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from sklearn import metrics\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.metrics import r2_score,confusion_matrix,mean_squared_error,accuracy_score,classification_report\n",
    "\n",
    "\n",
    "\n",
    "    #Import Data\n",
    "    pdp=pd.read_csv(\"parkinsons.data\")\n",
    "    display(pdp.head())\n",
    "\n",
    "\n",
    "\n",
    "    #Automatic Exploratory Data Analysis\n",
    "    display(pf.ProfileReport(pdp))\n",
    "\n",
    "\n",
    "    #Manual Exploratory Data Analysis(EDA)\n",
    "    print(pdp.describe())\n",
    "    print(pdp.info())\n",
    "    print(pdp.isnull().sum())\n",
    "    print(pdp.dtypes)\n",
    "    print(pdp.columns)\n",
    "\n",
    "\n",
    "    #Histogram for status column\n",
    "    status=pdp.status\n",
    "    status\n",
    "\n",
    "\n",
    "    plt.hist(pdp.status)\n",
    "    plt.xlabel(\"Status\")\n",
    "    plt.ylabel(\"Frequencies\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "##From the above histogram we find that the data contains maximum number of people who have Parkinsons disease\n",
    "\n",
    "    #BAR PLOT\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(pdp.status,pdp.HNR)\n",
    "    plt.xlabel(\"STATUS\")\n",
    "    plt.ylabel(\"HNR\")\n",
    "    plt.title(\"Status Vs HNR\")\n",
    "    plt.show()\n",
    "\n",
    "##From the above plot we observe that the people who have problem with their tone are less in number from people who have parkinsons disease\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(pdp.status,pdp.RPDE)\n",
    "    plt.xlabel(\"STATUS\")\n",
    "    plt.ylabel(\"RPDE\")\n",
    "    plt.title(\"Status Vs RPDE\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#From the above plot we observe that the people who have problem with their tone are more in number from people who have parkinsons disease\n",
    "\n",
    "    #Distribution PLot\n",
    "    warnings.filterwarnings('ignore')\n",
    "    rows=3\n",
    "    col=3\n",
    "    columns=pdp.columns\n",
    "    fig, ax=plt.subplots(nrows=rows,ncols=col,figsize=(16,14))\n",
    "    index=1\n",
    "    for i in range(rows):\n",
    "        for j in range(col):\n",
    "            sns.distplot(pdp[columns[index]],ax=ax[i][j])\n",
    "            index=index+1    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    #First 3 rows\n",
    "    pdp.head(3)\n",
    "\n",
    "\n",
    "    #Correlation\n",
    "    dfc=pdp.iloc[:,1:]\n",
    "    corr = dfc.corr()\n",
    "    display (corr)\n",
    "\n",
    "\n",
    "    #Heatmap on the above data\n",
    "    plt.figure(figsize=(35,30))\n",
    "    sns.set(font_scale=1.7)\n",
    "    sns.heatmap(corr,annot=True)\n",
    "    plt.show()\n",
    "\n",
    "    #MODEL PREDICTIONS\n",
    "\n",
    "    #Dropping name column\n",
    "    data=pdp.drop(columns='name')\n",
    "    data\n",
    "\n",
    "    #X and Y values\n",
    "    x=data.drop(labels=['status'],axis=1)\n",
    "    print(x.shape)\n",
    "    y=data.status\n",
    "    print(y.shape)\n",
    "\n",
    "    (195, 22)\n",
    "    (195,)\n",
    "\n",
    "\n",
    "    #Splitting train and test data\n",
    "    x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.8)\n",
    "    print(x.shape,y.shape)\n",
    "    print(x_train.shape,x_test.shape,y_train.shape,y_test.shape)\n",
    "\n",
    "    (195, 22) (195,)\n",
    "    (39, 22) (156, 22) (39,) (156,)\n",
    "\n",
    "#Logistic Regression\n",
    "\n",
    "    lr=LogisticRegression()\n",
    "    lr.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "    LogisticRegression()\n",
    "\n",
    "    y_pred_train=lr.predict(x_train)\n",
    "    print(y_pred_train)\n",
    "    print(y_pred_train.shape)\n",
    "    y_pred_test=lr.predict(x_test)\n",
    "    print(y_pred_test)\n",
    "    print(y_pred_test.shape)\n",
    "\n",
    "\n",
    "    #Accuracy of Model\n",
    "    accuracy_train=accuracy_score(y_train,y_pred_train)*100\n",
    "    print(\"Accuracy for logistic regression on train data is: \",accuracy_train)\n",
    "    accuracy_test=accuracy_score(y_test,y_pred_test)*100\n",
    "    print(\"Accuracy for logistic regression on test data is: \",accuracy_test)\n",
    "\n",
    "\n",
    "    #Confusion Matrix\n",
    "    print(\"confusion_matrix train is:\\n \", confusion_matrix(y_train, y_pred_train))\n",
    "    print(\"confusion_matrix test is:\\n \", confusion_matrix(y_test, y_pred_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Classification report\n",
    "    print('\\nClassification Report Train is ')\n",
    "    print(classification_report (y_train, y_pred_train))\n",
    "    print('\\nClassification Report Test is ')\n",
    "\n",
    "\n",
    "    #No. of wrong predictions\n",
    "    print((y_test !=y_pred_test).sum(),'/',((y_test ==y_pred_test).sum()+(y_test !=y_pred_test).sum()))\n",
    "    print('-'*50)\n",
    "    print((y_train !=y_pred_train).sum(),'/',((y_train ==y_pred_train).sum()+(y_train !=y_pred_train).sum()))\n",
    "    print('-'*50)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Kappa Score\n",
    "    print('KappaScore is: ', metrics.cohen_kappa_score(y_test,y_pred_test))\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "    #PLOT\n",
    "    sns.regplot(x=y_test,y=y_pred_test,scatter_kws={\"color\":'b'},logistic=True)\n",
    "    plt.show()\n",
    "\n",
    "#Random Forest Classifier\n",
    "\n",
    "\n",
    "    #Model Fitting\n",
    "    rfc=RandomForestClassifier()\n",
    "    rfc.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "    RandomForestClassifier()\n",
    "\n",
    "    #Prediction\n",
    "    y_pred1_train=rfc.predict(x_train)\n",
    "    print(y_pred1_train)\n",
    "    y_pred1_test=rfc.predict(x_test)\n",
    "    print(y_pred1_test)\n",
    "\n",
    "\n",
    "\n",
    "    #Accuracy of Model\n",
    "    accuracy_train1=accuracy_score(y_train,y_pred1_train)*100\n",
    "    print(\"Accuracy for Random Forest Classifier on train data is: \",accuracy_train1)\n",
    "    accuracy_test1=accuracy_score(y_test,y_pred1_test)*100\n",
    "    print(\"Accuracy for Random Forest Classifier on test data is: \",accuracy_test1)\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "    #Confusion Matrix\n",
    "    print(\"confusion_matrix train is:\\n \", confusion_matrix(y_train, y_pred1_train))\n",
    "    print(\"confusion_matrix test is:\\n \", confusion_matrix(y_test, y_pred1_test))\n",
    "\n",
    " \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "    #Classification Report\n",
    "    print('\\nClassification Report Train is ')\n",
    "    print(classification_report (y_train, y_pred1_train))\n",
    "    print('\\nClassification Report Test is ')\n",
    "    print(classification_report (y_test, y_pred1_test))\n",
    "\n",
    "    #PLOT\n",
    "    from sklearn.tree import plot_tree\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plot_tree(rfc.estimators_[0], filled=True)\n",
    "    plt.title('Random Forest Visualization')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "In \\[344\\]:\n",
    "\n",
    "    #Wrong Predictions\n",
    "    print((y_test !=y_pred1_test).sum(),'/',((y_test ==y_pred1_test).sum()+(y_test !=y_pred1_test).sum()))\n",
    "    print('-'*50)\n",
    "    print((y_train !=y_pred1_train).sum(),'/',((y_train ==y_pred1_train).sum()+(y_train !=y_pred1_train).sum()))\n",
    "    print('-'*50)\n",
    "\n",
    "\n",
    "    #KAppa Score\n",
    "    print('KappaScore is: ', metrics.cohen_kappa_score(y_test,y_pred1_test))\n",
    "\n",
    "    KappaScore is:  0.48130841121495327\n",
    "\n",
    "#Decision Tree Classifier\n",
    "\n",
    "\n",
    "    dtc=DecisionTreeClassifier()\n",
    "    dtc.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "    DecisionTreeClassifier()\n",
    "\n",
    "    y_pred2_train=dtc.predict(x_train)\n",
    "    print(y_pred1_train)\n",
    "    y_pred2_test=dtc.predict(x_test)\n",
    "    print(y_pred1_test)\n",
    "\n",
    "   \n",
    "\n",
    "    #Accuracy\n",
    "    accuracy_train2=accuracy_score(y_train,y_pred2_train)*100\n",
    "    print(\"Accuracy for Decision Tree Classifier on train data is: \",accuracy_train2)\n",
    "    accuracy_test2=accuracy_score(y_test,y_pred2_test)*100\n",
    "    print(\"Accuracy for Decision Tree Classifier on test data is: \",accuracy_test2)\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "    #Classification Report\n",
    "    print('\\nClassification Report Train is ')\n",
    "    print(classification_report (y_train, y_pred2_train))\n",
    "    print('\\nClassification Report Test is ')\n",
    "    print(classification_report (y_test, y_pred2_test))\n",
    "\n",
    "##In the above report we see that with help of Decision tree classifier the model has predicted exact values for train data set\n",
    "\n",
    "\n",
    "    #Wrong Predictions\n",
    "    print((y_test !=y_pred2_test).sum(),'/',((y_test ==y_pred2_test).sum()+(y_test !=y_pred2_test).sum()))\n",
    "    print('-'*50)\n",
    "    print((y_train !=y_pred2_train).sum(),'/',((y_train ==y_pred2_train).sum()+(y_train !=y_pred2_train).sum()))\n",
    "    print('-'*50)\n",
    "\n",
    "\n",
    "    #Kappa Score\n",
    "    print('KappaScore is: ', metrics.cohen_kappa_score(y_test,y_pred2_test))\n",
    "\n",
    "    \n",
    "\n",
    "    #Plot\n",
    "    class_names = pdp['status'].unique()\n",
    "    plt.figure(figsize=(20, 20)) \n",
    "    plot_tree(dtc, feature_names=x.columns,class_names=str(class_names), filled=True)\n",
    "    plt.title('Decision Tree Visualization')\n",
    "    plt.show()\n",
    "\n",
    "# KNN classifier\n",
    "\n",
    "\n",
    "    knn=KNeighborsClassifier()\n",
    "    knn.fit(x_train,y_train)\n",
    "    KNeighborsClassifier()\n",
    "\n",
    "\n",
    "    #Prediction\n",
    "    y_pred3_train=knn.predict(x_train)\n",
    "    print(y_pred3_train)\n",
    "    y_pred3_test=knn.predict(x_test)\n",
    "    print(y_pred3_test)\n",
    "\n",
    "\n",
    "    #Acccuracy\n",
    "    accuracy_train3=accuracy_score(y_train,y_pred3_train)*100\n",
    "    print(\"Accuracy for KNN classifier on train data is: \",accuracy_train3)\n",
    "    accuracy_test3=accuracy_score(y_test,y_pred3_test)*100\n",
    "    print(\"Accuracy for KNN Classifier on test data is: \",accuracy_test3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Wrong Predictions\n",
    "    print((y_test !=y_pred3_test).sum(),'/',((y_test ==y_pred3_test).sum()+(y_test !=y_pred3_test).sum()))\n",
    "    print('-'*50)\n",
    "    print((y_train !=y_pred3_train).sum(),'/',((y_train ==y_pred3_train).sum()+(y_train !=y_pred3_train).sum()))\n",
    "    print('-'*50)\n",
    "\n",
    "\n",
    "\n",
    "    #Kappa score\n",
    "    print('KappaScore is: ', metrics.cohen_kappa_score(y_test,y_pred3_test))\n",
    "  \n",
    "\n",
    "##Support Vector Classifier\n",
    "\n",
    "    svc=SVC()\n",
    "    svc.fit(x_train,y_train)\n",
    "\n",
    "    SVC()\n",
    "\n",
    "\n",
    "    y_pred4_train=svc.predict(x_train)\n",
    "    print(y_pred3_train)\n",
    "    y_pred4_test=svc.predict(x_test)\n",
    "    print(y_pred3_test)\n",
    "\n",
    "    #Accuracy\n",
    "    accuracy_train4=accuracy_score(y_train,y_pred4_train)*100\n",
    "    print(\"Accuracy for KNN classifier on train data is: \",accuracy_train4)\n",
    "    accuracy_test4=accuracy_score(y_test,y_pred4_test)*100\n",
    "    print(\"Accuracy for KNN Classifier on test data is: \",accuracy_test4)\n",
    "\n",
    "    #Wrong Predictions\n",
    "    print((y_test !=y_pred4_test).sum(),'/',((y_test ==y_pred4_test).sum()+(y_test !=y_pred4_test).sum()))\n",
    "    print('-'*50)\n",
    "    print((y_train !=y_pred4_train).sum(),'/',((y_train ==y_pred4_train).sum()+(y_train !=y_pred4_train).sum()))\n",
    "    print('-'*50)\n",
    "\n",
    "    #Kappa Score\n",
    "    print('KappaScore is: ', metrics.cohen_kappa_score(y_test,y_pred4_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4749afcc-1bac-4a88-a72c-29b3e5b29736",
   "metadata": {},
   "source": [
    "FROM ALL ABOVE MODELS WE CAN TELL THAT RANDOM FOREST CLASSIFIER HAS MORE ACCURACY PREDICTING THE STATUS OF THE DISEASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0c9d76-81ed-4dfb-b202-f13e90db31e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
